import re
import yaml
import feedparser
import socket
from datetime import datetime, timedelta, timezone
from dateutil import parser as dateparser
def clean_title(s: str):
    if not s:
        return ""
    return " ".join(s.split())


def load_keywords(path: str):
    kws = []
    with open(path, "r", encoding="utf-8") as f:
        for line in f:
            k = line.strip()
            if k and not k.startswith("#"):
                kws.append(k.lower())
    return kws


def text_match(text: str, keywords):
    t = (text or "").lower()
    return any(k in t for k in keywords)


def parse_dt(entry):
    for k in ("published", "updated", "created"):
        if k in entry and entry[k]:
            try:
                return dateparser.parse(entry[k])
            except Exception:
                pass
    for k in ("published_parsed", "updated_parsed"):
        if k in entry and entry[k]:
            try:
                return datetime(*entry[k][:6], tzinfo=timezone.utc)
            except Exception:
                pass
    return None


    



def fetch_items(feed_urls, keywords, start_dt, end_dt, limit=10):
    items = []
    seen = set()

    for url in feed_urls:
        socket.setdefaulttimeout(10)    
        try:
            d = feedparser.parse(url)
        except Exception:
            continue    

        entries = getattr(d, "entries", None) or []
        for e in entries[:50]:
            title = clean_title(getattr(e, "title", ""))
            link = getattr(e, "link", "")
            summary = getattr(e, "summary", "") or getattr(e, "description", "")

            if not title or not link:
                continue

            dt = parse_dt(e)
            if dt is not None:
                if dt.tzinfo is None:
                    dt = dt.replace(tzinfo=timezone.utc)
                dt_utc = dt.astimezone(timezone.utc)
                if not (start_dt <= dt_utc < end_dt):
                    continue

            if not (text_match(title, keywords) or text_match(summary, keywords)):
                continue

            key = title.lower()
            if key in seen:
                continue
            seen.add(key)

            items.append((dt or datetime(1970, 1, 1, tzinfo=timezone.utc), title, link))

    items.sort(key=lambda x: x[0], reverse=True)
    return items[:limit]


def main():
    # æ—¶é—´çª—å£ï¼šåŒ—äº¬æ—¶é—´æ˜¨å¤©
    tz_bj = timezone(timedelta(hours=8))
    now_bj = datetime.now(tz_bj)
    yday_bj = (now_bj - timedelta(days=1)).date()

    start_bj = datetime(yday_bj.year, yday_bj.month, yday_bj.day, 0, 0, 0, tzinfo=tz_bj)
    end_bj = start_bj + timedelta(days=1)
    start_utc = start_bj.astimezone(timezone.utc)
    end_utc = end_bj.astimezone(timezone.utc)

    # âœ… è¿™é‡Œæ˜¯ feeds çš„å”¯ä¸€å®šä¹‰ä½ç½®ï¼ˆéžå¸¸å…³é”®ï¼‰
    with open("config/feeds.yaml", "r", encoding="utf-8") as f:
        feeds = yaml.safe_load(f) or {}

    keywords = load_keywords("config/keywords.txt")

    global_items = fetch_items(
        feeds.get("global", []),
        keywords,
        start_utc,
        end_utc,
        limit=6
    )

    china_items = fetch_items(
        feeds.get("china", []),
        keywords,
        start_utc,
        end_utc,
        limit=6
    )

    # å…œåº•ï¼šå¦‚æžœä¸­å›½æ²¡æœ‰å‘½ä¸­å…³é”®è¯ï¼Œå–æœ€æ–° 3 æ¡
    if not china_items:
        china_items = fetch_items(
            feeds.get("china", []),
            [" "],
            start_utc,
            end_utc,
            limit=3
        )

    today_str = now_bj.strftime("%Y-%m-%d")
    yday_str = yday_bj.strftime("%Y-%m-%d")

    def fmt(items):
        if not items:
            return ["ï¼ˆæœªæŠ“åˆ°ç¬¦åˆæ¡ä»¶çš„æ–°é—»ï¼‰"]
        out = []
        for i, (_, title, link) in enumerate(items, 1):
            out.append(f"{i}. {title}\n{link}")
        return out

    msg = []
    msg.append(f"ðŸ¤– AIç¡¬ä»¶æ—¥æŠ¥ï½œ{today_str}ï¼ˆæŠ“å– {yday_str}ï¼‰")
    msg.append("")
    msg.append("ðŸŒ å…¨çƒ")
    msg.extend(fmt(global_items))
    msg.append("")
    msg.append("ðŸ‡¨ðŸ‡³ ä¸­å›½")
    msg.extend(fmt(china_items))
    msg.append("")
    msg.append("ðŸ“Œ è¯´æ˜Žï¼šæœ¬æ—¥æŠ¥ä¸º RSS + å…³é”®è¯ç­›é€‰ï¼ˆåŠè‡ªåŠ¨ï¼‰ã€‚")

    
    print("\n".join(msg))


from datetime import datetime
today_str = datetime.now().strftime("%Y-%m-%d")

global_items = []
china_items = []

# è¿™é‡Œæ˜¯ä½ æŠ“ RSSã€ç­›å…³é”®è¯ã€append title çš„é€»è¾‘

    

# ===== Generate Xiaohongshu-style daily =====
xhs = []
xhs.append(f"ðŸ¤– ä»Šå¤© AI ç¡¬ä»¶åœˆå‘ç”Ÿäº†ä»€ä¹ˆï¼Ÿï½œ{today_str}")
xhs.append("")
xhs.append("ä¸€å¥è¯å…ˆçœ‹è¶‹åŠ¿ï¼š")
xhs.append("ðŸ‘‰ èŠ¯ç‰‡ / ç®—åŠ› / ä¾›åº”é“¾ä¾ç„¶æ˜¯æ ¸å¿ƒä¸»çº¿ï¼Œä¸­å›½ç›¸å…³åŠ¨æ€å¯†åº¦æ˜Žæ˜¾ä¸Šå‡ã€‚")
xhs.append("")

xhs.append("ðŸŒ æµ·å¤– AI ç¡¬ä»¶åŠ¨æ€")
if global_items:
    for i, t in enumerate(global_items[:5], 1):
        xhsa = ["0ï¸âƒ£","1ï¸âƒ£","2ï¸âƒ£","3ï¸âƒ£","4ï¸âƒ£","5ï¸âƒ£","6ï¸âƒ£","7ï¸âƒ£","8ï¸âƒ£","9ï¸âƒ£","ðŸ”Ÿ"]
        xhs.append(f"{i}ï¸âƒ£ {t}" if i < 10 else f"{i}. {t}")
else:
    xhs.append("- ä»Šå¤©æ²¡æŠ“åˆ°ç¬¦åˆå…³é”®è¯çš„æµ·å¤–æ–°é—»ï¼Œå¯åœ¨ config/feeds.yaml æ”¾å®½å…³é”®è¯æˆ–åŠ æºã€‚")

xhs.append("")
xhs.append("ðŸ‡¨ðŸ‡³ ä¸­å›½ AI ç¡¬ä»¶è§‚å¯Ÿ")
if china_items:
    for i, t in enumerate(china_items[:5], 1):
        xhs.append(f"{i}ï¸âƒ£ {t}" if i < 10 else f"{i}. {t}")
else:
    xhs.append("- ä»Šå¤©æ²¡æŠ“åˆ°ç¬¦åˆå…³é”®è¯çš„ä¸­å›½æ–°é—»ï¼Œå¯åœ¨ config/feeds.yaml æ”¾å®½å…³é”®è¯æˆ–åŠ æºã€‚")

xhs.append("")
xhs.append("ðŸ“Œ ä»Šå¤©ä½ å¯ä»¥å…³æ³¨ï¼š")
xhs.append("- AI èŠ¯ç‰‡ä¸å†åªæ‹¼ç®—åŠ›ï¼Œè€Œæ˜¯ç³»ç»Ÿä¸Žç”Ÿæ€")
xhs.append("- ç¡¬ä»¶ä¸Žåº”ç”¨åœºæ™¯çš„ç»“åˆæ­£åœ¨åŠ é€Ÿ")
xhs.append("")
xhs.append("#AIç¡¬ä»¶ #èŠ¯ç‰‡ #ç®—åŠ› #ç§‘æŠ€èµ„è®¯ #æ¯æ—¥èµ„è®¯")

with open("daily_xhs.txt", "w", encoding="utf-8") as f:
    f.write("\n".join(xhs) + "\n")

 
    print("\n".join(out))


if __name__ == "__main__":
    main()
